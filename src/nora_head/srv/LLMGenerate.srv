# Copyright 2026 nanostation
# Licensed under the Apache License, Version 2.0

# Large Language Model text generation service
# Generates conversational responses using Llama

# User prompt / question
string prompt

# Conversation history (optional)
string[] conversation_history

# System prompt (optional)
string system_prompt

# Maximum tokens to generate
int32 max_tokens

# Temperature (0.0 to 2.0)
float32 temperature

# Top-p sampling (0.0 to 1.0)
float32 top_p

# Stop sequences (optional)
string[] stop_sequences

# Context data (optional JSON string)
string context_json

---

# Generated text response
string response

# Number of tokens generated
int32 tokens_generated

# Processing time (seconds)
float32 processing_time

# Model used (for logging)
string model_used

# Success flag
bool success

# Error message (empty if success=true)
string error_message

# Truncated flag (true if hit max_tokens limit)
bool truncated
